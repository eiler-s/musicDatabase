{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create modeled dataset with design principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of our data is already broken down into entities, so we just copied over the original tables from the staging dataset. The only problem with the original tables is that many fields were autodetected with type String because the data uses \"/N\" to represent nulls. Because of this, we were not able to cast columns to Integers, so we plan to accomplish this with Apache Beam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"musicbrainz_modeled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'earnest-keep-266820:musicbrainz_modeled' successfully created.\n"
     ]
    }
   ],
   "source": [
    "!bq --location=US mk --dataset {dataset_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "%%bigquery\n",
    "create table college_modeled.Student as\n",
    "select distinct sid, fname, lname, dob, 'CUR' as status\n",
    "from college_staging.Current_Students\n",
    "union all\n",
    "select distinct sid, fname, lname, cast(dob as string) as dob, 'PRO' as status\n",
    "from college_staging.New_Students;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Area as\n",
    "select area_id, area_name, area_type, begin_year, begin_month, begin_day, end_year, end_month, end_day, ended\n",
    "from musicbrainz_staging.Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Artist as\n",
    "select artist_id, artist_name, sort_name, begin_year, begin_month, begin_day, end_year, \n",
    "end_month, end_day, artist_type, area_id, gender, comment, ended, begin_area_id, end_area_id\n",
    "from musicbrainz_staging.Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Event as\n",
    "select event_id, event_name, begin_year, begin_month, begin_day, end_year, end_month, end_day, start_time, event_type,\n",
    "cancelled, setlist, comment\n",
    "from musicbrainz_staging.Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Label as\n",
    "select label_id, label_name, begin_year, begin_month, begin_day, end_year, end_month, end_day, label_code, label_type, \n",
    "label_area_id, comment, ended\n",
    "from musicbrainz_staging.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Place as\n",
    "select place_id, place_name, place_type, address, area_id, coordinates, comment, begin_year, begin_month, begin_day, end_year, end_month, end_day,\n",
    "ended\n",
    "from musicbrainz_staging.Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Recording as\n",
    "select rec_id, rec_name, artist_id, length, comment\n",
    "from musicbrainz_staging.Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Release as\n",
    "select rel_id, rel_name, artist_id, rel_group, status, packaging, language, script, barcode, comment, quality\n",
    "from musicbrainz_staging.Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Release_Group as\n",
    "select rel_gr_id, rel_gr_name, artist_id, rel_gr_type, comment\n",
    "from musicbrainz_staging.Release_Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.URL as\n",
    "select url_id, link\n",
    "from musicbrainz_staging.URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Work as\n",
    "select work_id, work_name, work_type, comment\n",
    "from musicbrainz_staging.Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Area_Type as\n",
    "select area_type_id, area_type, area_comment\n",
    "from musicbrainz_staging.Area_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Artist_Type as\n",
    "select artist_type_id, artist_type\n",
    "from musicbrainz_staging.Artist_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Event_Type as\n",
    "select event_type_id, type, comment\n",
    "from musicbrainz_staging.Event_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Gender as\n",
    "select gender_id, gender_type, comment\n",
    "from musicbrainz_staging.Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Label_Type as\n",
    "select label_id, label_type\n",
    "from musicbrainz_staging.Label_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Language as\n",
    "select language_id, language_name, lang_name_short\n",
    "from musicbrainz_staging.Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Place_Type as\n",
    "select place_type_id, place_name, comment\n",
    "from musicbrainz_staging.Place_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Release_Group_Type as\n",
    "select release_group_type_id, release_group_name\n",
    "from musicbrainz_staging.Release_Group_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Release_Status as\n",
    "select release_status_id, release_status_name, comment\n",
    "from musicbrainz_staging.Release_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table musicbrainz_modeled.Script as\n",
    "select script_id, short_name, script_code, script_name\n",
    "from musicbrainz_staging.Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run apache beam DirectRunner to clean 500 rows of the Area data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Interactive Beam requires Python 3.5.3+.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Area'> referenced by query SELECT * from musicbrainz_modeled.Area limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_b607baa85cd449b6841f7ea6019fe7d6 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.Area_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'area_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'area_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'area_type'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_year'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_month'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_day'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_year'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_month'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_day'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'ended'\n",
      " type: 'BOOL'>]>. Result: <Table\n",
      " creationTime: 1583693824506\n",
      " etag: 'uVeHOeMkmkDQhyklhtyVNg=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.Area_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583693824541\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'area_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'area_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'area_type'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'ended'\n",
      " type: 'BOOLEAN'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/Area_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Area_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run area_beam.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the tabel created in bigquery by Beam to ensure that FK and PK relationships still exist.\n",
    "First check if it has a valid primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0  500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct ab.area_id) from musicbrainz_modeled.Area_Beam as ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0  500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(ab.area_id) from musicbrainz_modeled.Area_Beam as ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then check if it still has a foreign key corresponding to the Area_Type table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Area_Type as aty\n",
    "right join musicbrainz_modeled.Area_Beam as ab\n",
    "on cast(aty.area_type_id as INT64) = ab.area_type\n",
    "where aty.area_type_id is null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"40\">Milestone 6</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this milestone, we ran dataflow transformations to cast values in our tables that could not be casted in SQL. We then checked that each of these tables has a primary key and that the foreign key relationships we discovered before still exist. We did not perform beam transformations on every table in our modeled dataset because many of our tables are 'type' tables and contain only a few rows and require no transformations (we checked with the TAs that this was okay!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AREA TRANSFORMATIONS\n",
    "Use dataflow to run the area transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/area-beam-dataflow.1583693977.124099/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/area-beam-dataflow.1583693977.124099/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpwl4ugpke', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/area-beam-dataflow.1583693977.124099/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/area-beam-dataflow.1583693977.124099/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/area-beam-dataflow.1583693977.124099/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpwl4ugpke', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/area-beam-dataflow.1583693977.124099/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/area-beam-dataflow.1583693977.124099/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/area-beam-dataflow.1583693977.124099/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-08T18:59:44.678890Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_11_59_43-17895068210843568770'\n",
      " location: 'us-central1'\n",
      " name: 'area-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-08T18:59:44.678890Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_11_59_43-17895068210843568770]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_11_59_43-17895068210843568770?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_11_59_43-17895068210843568770 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:43.543Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_11_59_43-17895068210843568770. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:43.544Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_11_59_43-17895068210843568770.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:46.975Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:47.739Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.284Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.310Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.334Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.359Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.tx/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.389Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.411Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.500Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.767Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.815Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.846Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.881Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.901Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.928Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.957Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:48.979Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Pair into Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.006Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.tx/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.029Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Reify into Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.054Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Write into Write input.tx/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.081Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.tx/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.107Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Extract into Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.130Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.149Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.173Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.193Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.217Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.238Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.262Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.287Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.312Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.333Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.360Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.384Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.404Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/InitializeWrite into Write input.tx/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.424Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.446Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.477Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.500Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.518Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.542Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.666Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.718Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.745Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.760Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.768Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.779Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.789Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.813Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.830Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.838Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.851Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.878Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.883Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:49.901Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_11_59_43-17895068210843568770 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T18:59:50.028Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:00:14.516Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:01:42.876Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:01:42.906Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.687Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.756Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.791Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.838Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.865Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.897Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.919Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.925Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.948Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.950Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.973Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:12.985Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.004Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.041Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.076Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.102Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.135Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.138Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.163Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.176Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.187Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.197Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.224Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.260Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.663Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.736Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.770Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.842Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.879Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.897Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.914Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.941Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.967Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:13.968Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:14.003Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:14.028Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:14.082Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:02:15.036Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_12298686771223127412\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_12298686771223127412\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:03:24.844Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_12298686771223127412\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:03:25.281Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_11044675625767221038\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_11044675625767221038\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:03:55.597Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_11044675625767221038\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:03:55.627Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_11044675625767221038\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:05.453Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_12298686771223127053\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_12298686771223127053\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:15.854Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_12298686771223127053\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:16.423Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:16.496Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:16.529Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:16.546Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:16.566Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:16.583Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:16.613Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:16.615Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:16.643Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:16.683Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:19.763Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:19.827Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:19.904Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:19.937Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:19.972Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:19.991Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:20.042Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:20.070Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:20.139Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:24.628Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:24.701Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:24.760Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:24.798Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:24.799Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:24.855Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:24.871Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:24.920Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:24.984Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.194Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.249Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.311Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.357Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.418Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.479Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.501Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.567Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.635Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.667Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.684Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.724Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.750Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.800Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:25.859Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:26.733Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:26.802Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:26.865Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:26.902Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:26.964Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:27.035Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:28.079Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:28.421Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:28.485Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:28.548Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:28.600Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:28.669Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:28.670Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:28.746Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:31.831Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:32.045Z: JOB_MESSAGE_DEBUG: Executing success step success40\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:32.430Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:32.609Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:04:32.645Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:06:17.556Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:06:17.602Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T19:06:17.632Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_11_59_43-17895068210843568770 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run area_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check primary key for full area table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f0_\n",
       "0  118076"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Area_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f0_\n",
       "0  118076"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct area_id) from musicbrainz_modeled.Area_Beam_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area foreign key relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(a.area_id) from musicbrainz_modeled.Area_Beam_DF as a\n",
    "right join musicbrainz_modeled.Place_Beam_DF as p on p.area_id = a.area_id\n",
    "where a.area_id is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(a.area_id) from musicbrainz_modeled.Area_Beam_DF as a\n",
    "right join musicbrainz_modeled.Label_Beam_DF as l on l.label_area_id = a.area_id\n",
    "where a.area_id is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(a.area_id) from musicbrainz_modeled.Area_Beam_DF as a\n",
    "right join musicbrainz_modeled.Area_Type as aty on aty.area_type_id = a.area_type\n",
    "where a.area_type is null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELEASE TRANSFORMATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Release'> referenced by query SELECT * from musicbrainz_modeled.Release limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_e73e329d886b4abe9ca737df714a41b3 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.Release_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_group'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'status'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'packaging'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'language'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'script'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'barcode'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'quality'\n",
      " type: 'INT64'>]>. Result: <Table\n",
      " creationTime: 1583722824550\n",
      " etag: 'PFCC82WOjAbVzjis6pwx/w=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.Release_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583722824591\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_group'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'status'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'packaging'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'language'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'script'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'barcode'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'quality'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/Release_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Release_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/release_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/release-beam-dataflow.1583723468.781853/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/release-beam-dataflow.1583723468.781853/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmprhst1az1', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/release-beam-dataflow.1583723468.781853/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/release-beam-dataflow.1583723468.781853/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/release-beam-dataflow.1583723468.781853/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmprhst1az1', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/release-beam-dataflow.1583723468.781853/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/release-beam-dataflow.1583723468.781853/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/release-beam-dataflow.1583723468.781853/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T03:11:14.244029Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_20_11_13-1077105416455285681'\n",
      " location: 'us-central1'\n",
      " name: 'release-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T03:11:14.244029Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_20_11_13-1077105416455285681]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_20_11_13-1077105416455285681?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_20_11_13-1077105416455285681 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:13.206Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_20_11_13-1077105416455285681.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:13.206Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_20_11_13-1077105416455285681. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:17.903Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:20.279Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:20.905Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:20.935Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:20.965Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:20.998Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.tx/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.041Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.072Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.196Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.472Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.512Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.543Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.575Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.609Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.644Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.679Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.710Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Pair into Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.736Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.tx/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.772Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Reify into Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.853Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Write into Write input.tx/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.889Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.tx/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.923Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Extract into Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:21.960Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.019Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.055Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.091Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.126Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.166Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.199Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.223Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.257Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.293Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.318Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.352Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.389Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/InitializeWrite into Write input.tx/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.428Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.461Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.503Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.535Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.571Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.613Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.812Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.898Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.935Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.948Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.961Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.986Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:22.998Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:23.032Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:23.049Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:23.058Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:23.092Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:23.112Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:23.131Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:23.180Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:23.223Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_20_11_13-1077105416455285681 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:11:47.451Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:12:59.489Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:12:59.521Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:24.883Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:24.964Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:24.991Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.078Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.114Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.130Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.154Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.195Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.215Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.242Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.275Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.317Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.717Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.799Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.845Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.923Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.959Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.970Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:25.984Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.006Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.047Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.086Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.089Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.155Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.613Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.704Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.745Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.830Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.875Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.902Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.910Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.936Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.962Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:26.997Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:27.034Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:27.074Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:27.114Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:13:28.391Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_15797253749254198720\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_15797253749254198720\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:15:07.435Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_15797253749254198720\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:15:08.024Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_369583473103705759\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_369583473103705759\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:15:38.378Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_369583473103705759\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:15:38.414Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_369583473103705759\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:17:22.785Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:17:58.807Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_15797253749254197351\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_15797253749254197351\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:29.370Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_15797253749254197351\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:29.841Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:29.923Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:29.950Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:29.970Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:29.983Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:30.002Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:30.039Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:30.046Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:30.115Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:30.154Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.152Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.222Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.294Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.325Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.346Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.371Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.424Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.459Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.524Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.741Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.802Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.873Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.906Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.925Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.993Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:33.997Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.055Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.130Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.565Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.629Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.705Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.742Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.760Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.815Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.861Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.897Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:34.966Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:36.769Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:36.850Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:36.929Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.002Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.088Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.174Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.200Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.296Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.446Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.503Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.574Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.635Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.652Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.717Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.797Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.853Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:37.942Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:38.025Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:38.700Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:39.232Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:40.048Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:40.127Z: JOB_MESSAGE_DEBUG: Executing success step success40\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:40.257Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:40.329Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:18:40.363Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:20:00.918Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:20:00.971Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T03:20:01.014Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_20_11_13-1077105416455285681 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/release_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check release primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2434536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  2434536"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Release_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2434536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  2434536"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct rb.rel_id) from musicbrainz_modeled.Release_Beam_DF as rb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check release foreign key relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(a.artist_id) from musicbrainz_modeled.Artist_Beam_DF as a\n",
    "right join musicbrainz_modeled.Release_Beam_DF as r on r.artist_id = a.artist_id\n",
    "where a.artist_id is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(r.language) from musicbrainz_modeled.Release_Beam_DF as r\n",
    "right join musicbrainz_modeled.Language_Beam_DF as l on l.language_id = r.language\n",
    "where r.language is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(r.status) from musicbrainz_modeled.Release_Beam_DF as r\n",
    "right join musicbrainz_modeled.Release_Status as rs on rs.release_status_id = r.status\n",
    "where r.status is null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LABEL BEAM TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Label'> referenced by query SELECT * from musicbrainz_modeled.Label limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_acffa90ad42a4c8992a9fe8d1cb07f68 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.Label_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'label_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'label_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_year'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_month'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_day'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_year'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_month'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_day'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'label_code'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'label_type'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'label_area_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'ended'\n",
      " type: 'BOOL'>]>. Result: <Table\n",
      " creationTime: 1583726604714\n",
      " etag: 'C2ZuSdOKp8l2XdEAiY0qOw=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.Label_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583726604769\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'label_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'label_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'label_code'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'label_type'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'label_area_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'ended'\n",
      " type: 'BOOLEAN'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/Label_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Label_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/label_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/label-beam-dataflow.1583727051.802232/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/label-beam-dataflow.1583727051.802232/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpsmcas6pb', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/label-beam-dataflow.1583727051.802232/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/label-beam-dataflow.1583727051.802232/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/label-beam-dataflow.1583727051.802232/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpsmcas6pb', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/label-beam-dataflow.1583727051.802232/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/label-beam-dataflow.1583727051.802232/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/label-beam-dataflow.1583727051.802232/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T04:10:57.230309Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_21_10_56-9388095462779392442'\n",
      " location: 'us-central1'\n",
      " name: 'label-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T04:10:57.230309Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_21_10_56-9388095462779392442]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_21_10_56-9388095462779392442?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_21_10_56-9388095462779392442 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:10:56.269Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_21_10_56-9388095462779392442.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:10:56.269Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_21_10_56-9388095462779392442. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:10:59.740Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:00.337Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-f.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.013Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.047Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.081Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.108Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.tx/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.152Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.183Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.331Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.653Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.699Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.736Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.783Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.822Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.866Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.912Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.945Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Pair into Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:01.983Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.tx/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.028Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Reify into Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.063Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Write into Write input.tx/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.099Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.tx/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.129Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Extract into Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.166Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.204Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.242Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.288Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.323Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.356Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.381Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.413Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.452Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.484Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.520Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.566Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.607Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/InitializeWrite into Write input.tx/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.645Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.689Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.733Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.759Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.803Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:02.836Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.289Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.411Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.446Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.458Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.483Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.494Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-f...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.596Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.634Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.666Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.676Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.706Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.747Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.765Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.803Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:03.840Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_21_10_56-9388095462779392442 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:11:26.799Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:34.400Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:34.438Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.232Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.304Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.339Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.401Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.407Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.444Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.467Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.470Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.492Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.512Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.522Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.541Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.575Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.608Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.644Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.678Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.705Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.729Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.738Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.754Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.786Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.807Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.818Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:04.873Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.258Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.334Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.359Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.415Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.440Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.458Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.475Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.498Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.511Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.528Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.560Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.603Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:05.639Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:06.854Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_9559281631400085929\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_9559281631400085929\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:15.194Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_9559281631400085929\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:15.686Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_13269763082239490155\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_13269763082239490155\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:45.958Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_13269763082239490155\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:45.995Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_13269763082239490155\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:00.416Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_9559281631400085602\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_9559281631400085602\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_9559281631400085602\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11.514Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11.599Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11.636Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11.655Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11.662Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11.691Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11.704Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11.710Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11.762Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:11.800Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:15.133Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:15.202Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:15.247Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:15.278Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:15.309Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:15.322Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:15.378Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:15.437Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:15.507Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:16.334Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:16.397Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:16.456Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:16.489Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:16.504Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:16.542Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:16.616Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:16.641Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:16.719Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.054Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.150Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.196Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.373Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.588Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.598Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.672Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.705Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.720Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.732Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.771Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.785Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.807Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.856Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:17.928Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:18.646Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:18.714Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:18.790Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:18.838Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:18.912Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:18.936Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:18.985Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:20.562Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:20.717Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:20.788Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:20.840Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:20.914Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:20.982Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:21.012Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:22.009Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:22.087Z: JOB_MESSAGE_DEBUG: Executing success step success40\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:22.206Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:22.272Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:15:22.308Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 2/2)\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:17:03.100Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:17:03.138Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:17:03.180Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_21_10_56-9388095462779392442 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/label_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that label still has a primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f0_\n",
       "0  174391"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Label_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f0_\n",
       "0  174391"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct lb.label_id) from musicbrainz_modeled.Label_Beam_DF as lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check foreign key relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(l.label_type) from musicbrainz_modeled.Label_Beam_DF as l\n",
    "right join musicbrainz_modeled.Label_Type as lt on lt.label_id = l.label_type\n",
    "where l.label_type is null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LANGUAGE BEAM TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Language'> referenced by query SELECT * from musicbrainz_modeled.Language limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_6700fb06815e4b7c9d32b605054e49ee does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.Language_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'language_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'language_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'lang_name_short'\n",
      " type: 'STRING'>]>. Result: <Table\n",
      " creationTime: 1583724929367\n",
      " etag: 'iswUtnwmjKb7LiJ9cIJd0Q=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.Language_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583724929417\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'language_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'language_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'lang_name_short'\n",
      " type: 'STRING'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/Language_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Language_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/language_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/language-beam-dataflow.1583731416.390911/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/language-beam-dataflow.1583731416.390911/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpf0cng3wk', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/language-beam-dataflow.1583731416.390911/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/language-beam-dataflow.1583731416.390911/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/language-beam-dataflow.1583731416.390911/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpf0cng3wk', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/language-beam-dataflow.1583731416.390911/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/language-beam-dataflow.1583731416.390911/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/language-beam-dataflow.1583731416.390911/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T05:23:43.546859Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_22_23_42-4398751147569228107'\n",
      " location: 'us-central1'\n",
      " name: 'language-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T05:23:43.546859Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_22_23_42-4398751147569228107]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_22_23_42-4398751147569228107?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_22_23_42-4398751147569228107 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:42.473Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_22_23_42-4398751147569228107.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:42.473Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_22_23_42-4398751147569228107. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:45.338Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:45.918Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-a.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:46.510Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:46.550Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:46.588Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:46.707Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.tx/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:46.746Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:46.783Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:46.921Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.180Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.222Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.255Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.285Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.312Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.352Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.378Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.414Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Pair into Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.438Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.tx/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.477Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Reify into Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.516Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Write into Write input.tx/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.552Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.tx/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.586Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Extract into Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.625Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.665Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.699Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.734Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.770Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.795Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.821Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.860Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.897Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.945Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:47.982Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.019Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.048Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/InitializeWrite into Write input.tx/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.079Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.115Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.150Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.184Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.211Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.243Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.512Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.580Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.617Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.629Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.657Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.657Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-a...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.682Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.716Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.732Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.753Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.770Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.799Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.806Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.827Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_22_23_42-4398751147569228107 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:23:48.862Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:24:12.892Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:25:31.317Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:25:31.352Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:25:59.957Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.025Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.057Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.138Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.161Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.194Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.195Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.216Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.250Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.255Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.294Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:00.332Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:01.895Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:01.963Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:01.992Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.060Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.091Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.112Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.127Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.144Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.188Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.209Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.218Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.230Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.263Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.294Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.328Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.388Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.420Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.444Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.459Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.482Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.508Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.517Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.555Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.591Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:02.629Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:26:03.539Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_11484809183737455105\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_11484809183737455105\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:12.529Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_11484809183737455105\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:13.154Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_10371488078845184043\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_10371488078845184043\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:43.444Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_10371488078845184043\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:43.477Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_10371488078845184043\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:46.805Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_11484809183737456118\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_11484809183737456118\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:57.209Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_11484809183737456118\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:57.895Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:57.967Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:57.994Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:58.011Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:58.035Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:58.039Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:58.069Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:58.077Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:58.106Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:58.143Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:01.272Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:01.345Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:01.417Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:01.452Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:01.467Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:01.499Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:01.538Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:01.576Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:01.637Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.678Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.746Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.775Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.815Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.853Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.858Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.879Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.910Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.929Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.967Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:04.990Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.015Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.022Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.039Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.072Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.110Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.139Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.195Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.337Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.402Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.468Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.526Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.594Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:05.653Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.540Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.611Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.653Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.681Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.717Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.719Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.721Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.777Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.801Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.852Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.869Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.908Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.982Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.016Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.930Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.994Z: JOB_MESSAGE_DEBUG: Executing success step success40\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:10.112Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:10.170Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:10.207Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:30.381Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:30.412Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:30.435Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_22_23_42-4398751147569228107 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/language_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that language has a valid primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0_\n",
       "0  7843"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Language_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0_\n",
       "0  7843"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct lb.language_id) from musicbrainz_modeled.Language_Beam_DF as lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLACE BEAM TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Place'> referenced by query SELECT * from musicbrainz_modeled.Place limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_99071fc65784493ea037e20c2cceb8be does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.Place_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_type'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'address'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'area_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'coordinates'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_year'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_month'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_day'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_year'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_month'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_day'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'ended'\n",
      " type: 'BOOL'>]>. Result: <Table\n",
      " creationTime: 1583725871501\n",
      " etag: 'IYDZ1QsPboeOQpknhqyA3Q=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.Place_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583725871526\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_type'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'address'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'area_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'coordinates'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'ended'\n",
      " type: 'BOOLEAN'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/Place_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Place_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/place_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/place-beam-dataflow.1583731929.648058/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/place-beam-dataflow.1583731929.648058/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpnmybf78s', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/place-beam-dataflow.1583731929.648058/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/place-beam-dataflow.1583731929.648058/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/place-beam-dataflow.1583731929.648058/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpnmybf78s', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/place-beam-dataflow.1583731929.648058/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/place-beam-dataflow.1583731929.648058/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/place-beam-dataflow.1583731929.648058/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T05:32:15.126492Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_22_32_14-285589134233253281'\n",
      " location: 'us-central1'\n",
      " name: 'place-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T05:32:15.126492Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_22_32_14-285589134233253281]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_22_32_14-285589134233253281?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_22_32_14-285589134233253281 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:14.079Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_22_32_14-285589134233253281.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:14.079Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_22_32_14-285589134233253281. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:42.010Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:43.083Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-f.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:43.760Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:43.787Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:43.808Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:43.839Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.tx/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:43.875Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:43.902Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.005Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.248Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.275Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.299Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.322Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.347Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.373Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.397Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.426Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Pair into Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.447Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.tx/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.474Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Reify into Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.495Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Write into Write input.tx/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.524Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.tx/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.553Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Extract into Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.578Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.605Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.627Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.650Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.672Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.694Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.716Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.743Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.764Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.793Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.822Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.845Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.866Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/InitializeWrite into Write input.tx/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.891Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.914Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:44.945Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.006Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.036Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.059Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.638Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.701Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.728Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.740Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.750Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.770Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-f...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.772Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.800Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.821Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.826Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.840Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.874Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.874Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.898Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:32:45.937Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_22_32_14-285589134233253281 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:33:13.691Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:23.657Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:23.681Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.638Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.693Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.724Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.774Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.803Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.821Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.835Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.854Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.877Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.888Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.914Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:50.943Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:51.920Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.006Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.045Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.107Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.139Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.168Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.208Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.260Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.274Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.287Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.314Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.340Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.867Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.921Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:52.947Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:53Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:53.029Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:53.045Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:53.051Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:53.070Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:53.101Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:53.116Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:53.143Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:53.179Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:53.213Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:34:54.204Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_4138926041635894868\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_4138926041635894868\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:00.681Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_4138926041635894868\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:01.033Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_8342734220114326759\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_8342734220114326759\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:31.385Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_8342734220114326759\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:31.417Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_8342734220114326759\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:37.515Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_4138926041635896823\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_4138926041635896823\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:47.968Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_4138926041635896823\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:48.483Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:48.546Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:48.574Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:48.593Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:48.605Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:48.613Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:48.646Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:48.650Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:48.671Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:48.704Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:51.820Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:51.880Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:51.971Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:52.007Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:52.022Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:52.055Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:52.083Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:52.110Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:52.170Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:53.179Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:53.358Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:53.594Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:53.652Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:53.693Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:53.715Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:53.849Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:53.857Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:53.916Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:53.983Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:54.050Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:54.106Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:54.139Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:54.166Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:54.187Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:54.239Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:54.294Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:54.400Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:55.091Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:55.218Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:55.330Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:55.416Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:55.514Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:55.606Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:56.090Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:56.162Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:56.253Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:56.297Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:56.343Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:56.410Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:56.767Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:56.861Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:56.928Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:57.140Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:57.233Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:57.338Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:57.411Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:58.565Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:59.762Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:59.816Z: JOB_MESSAGE_DEBUG: Executing success step success40\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:59.922Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:59.972Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:36:59.999Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:38:29.608Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:38:29.640Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:38:29.670Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_22_32_14-285589134233253281 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/place_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that place has a valid primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  39888"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Place_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  39888"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct pb.place_id) from musicbrainz_modeled.Place_Beam_DF as pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check foreign keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "select count(p.place_type) from musicbrainz_modeled.Place_Beam_DF as p\n",
    "right join musicbrainz_modeled.Place_Type as pt on pt.place_type_id = p.place_type\n",
    "where p.place_type is null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORDING BEAM TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Recording'> referenced by query SELECT * from musicbrainz_modeled.Recording limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_7e9ba371937e4ba1943e62bde620b824 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.Recording_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rec_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rec_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'length'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>]>. Result: <Table\n",
      " creationTime: 1583728004583\n",
      " etag: '+k6AFz5j8Kccb8U59TKQWg=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.Recording_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583728004622\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rec_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rec_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'length'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/Recording_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Recording_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/recording_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/recording-beam-dataflow.1583813459.364519/pipeline.pb...\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/recording-beam-dataflow.1583813459.364519/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmprldxpbij', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/recording-beam-dataflow.1583813459.364519/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/recording-beam-dataflow.1583813459.364519/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/recording-beam-dataflow.1583813459.364519/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmprldxpbij', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/recording-beam-dataflow.1583813459.364519/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/recording-beam-dataflow.1583813459.364519/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/recording-beam-dataflow.1583813459.364519/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 0 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-10T04:11:04.916375Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-09_21_11_03-2345737668644934210'\n",
      " location: 'us-central1'\n",
      " name: 'recording-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-10T04:11:04.916375Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-09_21_11_03-2345737668644934210]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-09_21_11_03-2345737668644934210?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_21_11_03-2345737668644934210 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:03.735Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-09_21_11_03-2345737668644934210.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:03.735Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-09_21_11_03-2345737668644934210. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:08.597Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:09.645Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-a.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:10.237Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:10.279Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:10.319Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:10.355Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.tx/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:10.407Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:10.450Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:10.587Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:10.918Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:10.963Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.012Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.048Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.076Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.104Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.128Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.168Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Pair into Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.205Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.tx/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.247Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Reify into Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.288Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Write into Write input.tx/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.319Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.tx/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.347Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Extract into Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.378Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.419Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.462Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.531Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.573Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.624Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.662Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.703Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.740Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.779Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.818Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.857Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.889Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/InitializeWrite into Write input.tx/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.924Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:11.967Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.010Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.047Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.080Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.118Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.361Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.463Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.485Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.509Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.526Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.547Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-a...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.576Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.610Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.653Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.686Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.695Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.739Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.769Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.804Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:12.840Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_21_11_03-2345737668644934210 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:11:38.077Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:12:51.875Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:12:51.968Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.398Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.487Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.536Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.588Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.614Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.678Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.696Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.705Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.769Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.798Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.821Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.902Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:20.957Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.005Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.032Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.059Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.086Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.101Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.108Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.130Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.182Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.189Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.255Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.322Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.549Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.601Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.693Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.848Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.900Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.950Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.974Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:21.986Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:22.037Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:22.048Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:22.075Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:22.102Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:22.150Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:13:24.424Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_3937298808097420177\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_3937298808097420177\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:15:23.942Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_3937298808097420177\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:15:24.365Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_12279300662847365298\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_12279300662847365298\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:16:24.823Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_12279300662847365298\" observed total of 3 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:16:24.890Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_12279300662847365298\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:17:12.322Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:17:20.053Z: JOB_MESSAGE_BASIC: Autoscaling: Resizing worker pool from 1 to 2.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:17:25.780Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 2 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:17:48.500Z: JOB_MESSAGE_BASIC: Autoscaling: Resizing worker pool from 2 to 3.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-10T04:17:54.158Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 3 based on the rate of progress in the currently running step(s).\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/recording_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that recording has a primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21874183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f0_\n",
       "0  21874183"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Recording_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21874183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f0_\n",
       "0  21874183"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct rb.rec_id) from musicbrainz_modeled.Recording_Beam_DF as rb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELEASE GROUP TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Release_Group'> referenced by query SELECT * from musicbrainz_modeled.Release_Group limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_eaac7fbe5cb44b58a0a6bab5c44ebee9 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.Release_Group_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_gr_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_gr_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_gr_type'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>]>. Result: <Table\n",
      " creationTime: 1583730850598\n",
      " etag: 'xS9IdK9EYjCFqpF0qs386g=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.Release_Group_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583730850637\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_gr_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_gr_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'rel_gr_type'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/Release_Group_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Release_Group_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/release_group_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/release-group-beam-dataflow.1583733603.802385/pipeline.pb...\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/release-group-beam-dataflow.1583733603.802385/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpv3utoyj5', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/release-group-beam-dataflow.1583733603.802385/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/release-group-beam-dataflow.1583733603.802385/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/release-group-beam-dataflow.1583733603.802385/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpv3utoyj5', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/release-group-beam-dataflow.1583733603.802385/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/release-group-beam-dataflow.1583733603.802385/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/release-group-beam-dataflow.1583733603.802385/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T06:00:09.259015Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_23_00_08-2595161948870569711'\n",
      " location: 'us-central1'\n",
      " name: 'release-group-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T06:00:09.259015Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_23_00_08-2595161948870569711]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_23_00_08-2595161948870569711?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_23_00_08-2595161948870569711 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:08.208Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_23_00_08-2595161948870569711.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:08.208Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_23_00_08-2595161948870569711. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:13.285Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:13.916Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-f.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:14.420Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:14.508Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:14.563Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:14.619Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.tx/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:14.661Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:14.685Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:14.822Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.066Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.093Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.123Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.151Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.174Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.205Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.228Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.262Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Pair into Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.298Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.tx/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.335Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Reify into Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.370Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Write into Write input.tx/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.403Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.tx/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.431Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Extract into Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.465Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.502Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.574Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.616Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.653Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.694Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.718Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.749Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.782Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.817Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.853Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.887Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.928Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/InitializeWrite into Write input.tx/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.950Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:15.982Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.008Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.038Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.082Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.113Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.378Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.450Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.485Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.496Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.522Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.534Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-f...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.556Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.588Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.604Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.610Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.638Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.660Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.660Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.706Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:16.739Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_23_00_08-2595161948870569711 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:00:40.418Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:01:54.945Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:01:54.981Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.346Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.421Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.445Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.514Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.551Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.583Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.605Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.611Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.635Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.683Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.715Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:21.748Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.373Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.430Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.442Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.478Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.526Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.550Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.575Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.588Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.624Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.630Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.646Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.655Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.692Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.723Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.749Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.781Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.803Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.815Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.848Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.849Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.867Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.881Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.914Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.947Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:23.990Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:02:25.139Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_4932404873204240658\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_4932404873204240658\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:04:30.398Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_4932404873204240658\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:04:30.975Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_2710138966340808063\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_2710138966340808063\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:05:01.368Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_2710138966340808063\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:05:01.400Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_2710138966340808063\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:16.356Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:17.815Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_4932404873204241811\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_4932404873204241811\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:48.465Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_4932404873204241811\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:48.997Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:49.055Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:49.089Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:49.094Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:49.127Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:49.131Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:49.161Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:49.167Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:49.194Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:49.226Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.012Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.101Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.157Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.194Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.200Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.242Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.259Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.294Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.327Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.352Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.384Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.441Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.474Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.479Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.518Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.526Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.570Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.578Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.624Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.655Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.708Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.742Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.755Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.787Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.813Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.851Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:52.903Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.383Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.435Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.488Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.532Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.593Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.635Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.653Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.683Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.735Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.782Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.837Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:54.896Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:56.062Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:56.069Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:56.124Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:56.183Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:56.220Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:56.280Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:56.333Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:56.848Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:58.349Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:58.414Z: JOB_MESSAGE_DEBUG: Executing success step success40\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:58.525Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:58.568Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:06:58.588Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:08:04.355Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:08:04.393Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:08:04.417Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_23_00_08-2595161948870569711 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/release_group_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that release group has a primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1923172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  1923172"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Release_Group_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1923172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  1923172"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct rgb.rel_gr_id) from musicbrainz_modeled.Release_Group_Beam_DF as rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find foreign key relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(rg.rel_gr_type) from musicbrainz_modeled.Release_Group_Beam_DF as rg\n",
    "right join musicbrainz_modeled.Release_Group_Type as rgt on rgt.release_group_type_id = rg.rel_gr_type\n",
    "where rg.rel_gr_type is null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORK TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Work'> referenced by query SELECT * from musicbrainz_modeled.Work limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_5eb6b89332144fd1bc756e200c886e8e does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.Work_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'work_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'work_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'work_type'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>]>. Result: <Table\n",
      " creationTime: 1583785114979\n",
      " etag: 'omqge1uiv6ayz+c19OHcqQ=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.Work_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583785115004\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'work_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'work_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'work_type'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/Work_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Work_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/work_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/work-beam-dataflow.1583734219.011242/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/work-beam-dataflow.1583734219.011242/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpgp4v45ww', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/work-beam-dataflow.1583734219.011242/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/work-beam-dataflow.1583734219.011242/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/work-beam-dataflow.1583734219.011242/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpgp4v45ww', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/work-beam-dataflow.1583734219.011242/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/work-beam-dataflow.1583734219.011242/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/work-beam-dataflow.1583734219.011242/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T06:10:24.430500Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_23_10_23-16854902776042582099'\n",
      " location: 'us-central1'\n",
      " name: 'work-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T06:10:24.430500Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_23_10_23-16854902776042582099]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_23_10_23-16854902776042582099?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_23_10_23-16854902776042582099 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:23.527Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_23_10_23-16854902776042582099. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:23.527Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_23_10_23-16854902776042582099.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:31.483Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:32.004Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-f.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:32.628Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:32.674Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:32.710Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:32.746Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.tx/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:32.787Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:32.822Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:32.948Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.436Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.479Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.564Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.627Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.710Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.751Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.778Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.814Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Pair into Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.870Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.tx/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.939Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Reify into Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:33.984Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Write into Write input.tx/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.026Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.tx/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.062Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Extract into Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.096Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.129Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.164Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.187Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.219Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.252Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.283Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.351Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.375Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.399Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.433Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.467Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.492Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/InitializeWrite into Write input.tx/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.529Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.554Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.592Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.623Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.660Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.693Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.878Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_23_10_23-16854902776042582099 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.938Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.973Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:34.987Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.005Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.027Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-f...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.039Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.073Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.085Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.107Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.114Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.143Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.150Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.177Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:10:35.223Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:11:06.404Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:19.711Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:19.745Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:46.997Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.061Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.095Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.163Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.195Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.214Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.222Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.256Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.278Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.282Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.314Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:47.360Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.080Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.158Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.195Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.264Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.296Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.314Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.331Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.357Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.375Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.382Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.391Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.432Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.459Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.491Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.525Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.566Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.600Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.617Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.640Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.666Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.681Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.694Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.741Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.771Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:48.804Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:12:49.757Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_1282626246745172804\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_1282626246745172804\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:14:06.371Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_1282626246745172804\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:14:06.886Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_13304514210899819138\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_13304514210899819138\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:14:37.180Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_13304514210899819138\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:14:37.216Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_13304514210899819138\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T06:15:23.836Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_1282626246745172707\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_1282626246745172707\".\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/work_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check primary key relationships for work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1270291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  1270291"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Work_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1270291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  1270291"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct wb.work_id) from musicbrainz_modeled.Work_Beam_DF as wb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean URL Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Interactive Beam requires Python 3.5.3+.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'URL'> referenced by query SELECT * from musicbrainz_modeled.URL limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_42feb76796db4011a33925477ad0ee7a does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.11 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.URL_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'url_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'link'\n",
      " type: 'STRING'>]>. Result: <Table\n",
      " creationTime: 1583778883611\n",
      " etag: '9LvmtgfgV7vdkupY28C0fg=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.URL_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583778883648\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'url_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'link'\n",
      " type: 'STRING'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/URL_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'URL_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/URL_Beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/url-beam-dataflow.1583779211.645743/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/url-beam-dataflow.1583779211.645743/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpx4ln0j47', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/url-beam-dataflow.1583779211.645743/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/url-beam-dataflow.1583779211.645743/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/url-beam-dataflow.1583779211.645743/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpx4ln0j47', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/url-beam-dataflow.1583779211.645743/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/url-beam-dataflow.1583779211.645743/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/url-beam-dataflow.1583779211.645743/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T18:40:18.737174Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-09_11_40_17-16344497063012854251'\n",
      " location: 'us-central1'\n",
      " name: 'url-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T18:40:18.737174Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-09_11_40_17-16344497063012854251]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-09_11_40_17-16344497063012854251?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_11_40_17-16344497063012854251 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:17.697Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-09_11_40_17-16344497063012854251. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:17.697Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-09_11_40_17-16344497063012854251.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:21.104Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:21.851Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-f.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:22.526Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:22.569Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:22.602Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:22.632Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.txt/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:22.683Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:22.709Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:22.833Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.097Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.136Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.164Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.txt/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.196Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.221Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.245Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.273Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.299Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.txt/Write/WriteImpl/Pair into Write input.txt/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.328Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.txt/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.txt/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.355Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.txt/Write/WriteImpl/GroupByKey/Reify into Write input.txt/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.385Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.txt/Write/WriteImpl/GroupByKey/Write into Write input.txt/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.409Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.txt/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.txt/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.441Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.txt/Write/WriteImpl/Extract into Write input.txt/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.467Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.489Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.514Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.546Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.580Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.604Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.631Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.666Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.690Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.722Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.750Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.784Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.811Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.txt/Write/WriteImpl/InitializeWrite into Write input.txt/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.833Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.863Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.890Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.918Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.948Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:23.973Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_11_40_17-16344497063012854251 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.125Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.195Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.284Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.315Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.333Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/DoOnce/Read+Write input.txt/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.357Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-f...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.385Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.424Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.447Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.457Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.521Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.585Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.585Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.674Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:24.705Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:40:51.432Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:10.897Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:10.928Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.099Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.214Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.267Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.330Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.358Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.380Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.384Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.405Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.430Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.440Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.471Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:41.494Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.169Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/DoOnce/Read+Write input.txt/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.231Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.265Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.323Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.350Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.365Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.377Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.392Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.418Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.418Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.457Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:42.570Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.317Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.372Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.414Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.567Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.631Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.660Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.720Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.755Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.859Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.881Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.920Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.972Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:43.997Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.txt/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.txt/Write/WriteImpl/Pair+Write input.txt/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.txt/Write/WriteImpl/GroupByKey/Reify+Write input.txt/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:42:44.835Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_13030764219581648193\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_13030764219581648193\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:44:25.809Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_13030764219581648193\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:44:26.364Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_3148261407182088733\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_3148261407182088733\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:45:26.716Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_3148261407182088733\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:45:26.748Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_3148261407182088733\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:46:24.112Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:48:33.192Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_13030764219581648294\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_13030764219581648294\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:03.892Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_13030764219581648294\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:04.319Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Replace t/f and n+Write input.txt/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.txt/Write/WriteImpl/Pair+Write input.txt/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.txt/Write/WriteImpl/GroupByKey/Reify+Write input.txt/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:04.384Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:04.424Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:04.453Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:04.482Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:04.493Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:04.511Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:04.527Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:04.539Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:04.580Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/GroupByKey/Read+Write input.txt/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.txt/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:05.839Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.001Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.027Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.102Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.129Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.157Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.184Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.185Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.203Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.214Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.223Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.238Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.257Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.265Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.296Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.308Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/GroupByKey/Read+Write input.txt/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.txt/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.318Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.344Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.372Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.405Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.433Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.460Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.481Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.496Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.539Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.568Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:06.622Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:07.926Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:07.980Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:07.992Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.185Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.228Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.246Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.291Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.307Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.318Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.331Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.381Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.413Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.446Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.459Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.494Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.529Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.561Z: JOB_MESSAGE_DEBUG: Value \"Write input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:08.627Z: JOB_MESSAGE_BASIC: Executing operation Write input.txt/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:09.688Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:09.724Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:09.778Z: JOB_MESSAGE_BASIC: Finished operation Write input.txt/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:09.837Z: JOB_MESSAGE_DEBUG: Executing success step success40\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:09.972Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:10.035Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:49:10.070Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:50:33.054Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:50:33.090Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T18:50:33.118Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_11_40_17-16344497063012854251 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/URL_Beam_Dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check URL Primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6373091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  6373091"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.URL_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6373091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  6373091"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct url_id) from musicbrainz_modeled.URL_Beam_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAN EVENT TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Event'> referenced by query SELECT * from musicbrainz_modeled.Event limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_ff97992531c3445cabbadb960b625fc0 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.Event_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'event_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'event_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_year'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_month'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_day'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_year'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_month'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_day'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'start_time'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'event_type'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'cancelled'\n",
      " type: 'BOOL'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'setlist'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>]>. Result: <Table\n",
      " creationTime: 1583780411403\n",
      " etag: 'zhMLCudyKiN7vqYRVdz89A=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.Event_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583780411459\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'event_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'event_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'start_time'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'event_type'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'cancelled'\n",
      " type: 'BOOLEAN'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'setlist'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/Event_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Event_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/Event_Beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/event-beam-dataflow.1583780672.895681/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/event-beam-dataflow.1583780672.895681/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpx822fdn7', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/event-beam-dataflow.1583780672.895681/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/event-beam-dataflow.1583780672.895681/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/event-beam-dataflow.1583780672.895681/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpx822fdn7', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/event-beam-dataflow.1583780672.895681/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/event-beam-dataflow.1583780672.895681/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/event-beam-dataflow.1583780672.895681/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 0 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T19:04:38.065642Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-09_12_04_37-13023396250879121932'\n",
      " location: 'us-central1'\n",
      " name: 'event-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T19:04:38.065642Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-09_12_04_37-13023396250879121932]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-09_12_04_37-13023396250879121932?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_12_04_37-13023396250879121932 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:37.199Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-09_12_04_37-13023396250879121932.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:37.199Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-09_12_04_37-13023396250879121932. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:40.479Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:41.173Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:41.729Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:41.777Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:41.809Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:41.842Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.tx/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:41.881Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:41.912Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.025Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.287Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.328Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.362Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.395Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.434Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.467Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.496Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.530Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Pair into Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.557Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.tx/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.592Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Reify into Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.630Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Write into Write input.tx/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.664Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.tx/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.693Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Extract into Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.725Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.758Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.789Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.825Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.862Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.895Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.934Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:42.986Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.092Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.156Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.241Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.300Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.381Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/InitializeWrite into Write input.tx/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.443Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.548Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.652Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.758Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.870Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:43.983Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.100Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.385Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.446Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.450Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.492Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.504Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.554Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.596Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.634Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.639Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.669Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.716Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.722Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.763Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:04:45.817Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_12_04_37-13023396250879121932 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:05:10.218Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:06:40.584Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:06:40.624Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.443Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.453Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.513Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.547Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.548Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.584Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.617Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.649Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.684Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.703Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.718Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.734Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.758Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.781Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.797Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.832Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.864Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.891Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.898Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.927Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.933Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.965Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:09.966Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.005Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.041Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.069Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.081Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.107Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.120Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.135Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.155Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.160Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.198Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.232Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.265Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.301Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:10.330Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:07:11.415Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_2587613075550719084\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_2587613075550719084\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:08:22.588Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_2587613075550719084\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:08:22.984Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_4878041567606359345\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_4878041567606359345\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:08:53.329Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_4878041567606359345\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:08:53.408Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_4878041567606359345\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:08:59.340Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_2587613075550718231\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_2587613075550718231\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:09.745Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_2587613075550718231\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:10.237Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:10.296Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:10.323Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:10.335Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:10.342Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:10.358Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:10.384Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:10.388Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:10.413Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:10.437Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:13.598Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:13.652Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:13.697Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:13.720Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:13.735Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:13.786Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:13.844Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:13.893Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:13.939Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:16.331Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:16.397Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:16.460Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:16.494Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:16.512Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:16.550Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:16.572Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:16.623Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:16.718Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:16.955Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.013Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.074Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.106Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.132Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.155Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.196Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.222Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.294Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.654Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.715Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.789Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.857Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.923Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:17.982Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:19.270Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:19.340Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:19.408Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:19.493Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:19.715Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:20.077Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:20.914Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:20.976Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:21.043Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:21.099Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:21.132Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:21.176Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:21.249Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:23.202Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:23.445Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:23.498Z: JOB_MESSAGE_DEBUG: Executing success step success40\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:23.614Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:23.675Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:09:23.712Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:11:08.573Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:11:08.659Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:11:08.696Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_12_04_37-13023396250879121932 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/Event_Beam_Dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check event primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  40693"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Event_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  40693"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct event_id) from musicbrainz_modeled.Event_Beam_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check foreign keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(e.event_id) from musicbrainz_modeled.Event_Beam_DF as e\n",
    "right join musicbrainz_modeled.Event_Type as et on et.event_type_id = e.event_type\n",
    "where e.event_type is null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAN ARTIST TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Artist'> referenced by query SELECT * from musicbrainz_modeled.Artist limit 500\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset earnest-keep-266820:temp_dataset_796b6087a81a48cf96587107a00b1d0d does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Waiting on response from query: SELECT * from musicbrainz_modeled.Artist limit 500 ...\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Waiting on response from query: SELECT * from musicbrainz_modeled.Artist limit 500 ...\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table earnest-keep-266820.musicbrainz_modeled.Artist_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'sort_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_year'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_month'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_day'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_year'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_month'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_day'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_type'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'area_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'gender'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'ended'\n",
      " type: 'BOOL'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_area_id'\n",
      " type: 'INT64'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_area_id'\n",
      " type: 'INT64'>]>. Result: <Table\n",
      " creationTime: 1583781158080\n",
      " etag: 'ARnqdEQFb2qHzMxEZU7IPg=='\n",
      " id: 'earnest-keep-266820:musicbrainz_modeled.Artist_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583781158112\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'sort_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'artist_type'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'area_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'gender'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'comment'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'ended'\n",
      " type: 'BOOLEAN'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'begin_area_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'end_area_id'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/earnest-keep-266820/datasets/musicbrainz_modeled/tables/Artist_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'musicbrainz_modeled'\n",
      " projectId: 'earnest-keep-266820'\n",
      " tableId: 'Artist_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/Artist_Beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/artist-beam-dataflow.1583781343.474323/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/artist-beam-dataflow.1583781343.474323/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpll6kh1wa', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://jeffersonballers-yeet/staging/artist-beam-dataflow.1583781343.474323/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/artist-beam-dataflow.1583781343.474323/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/artist-beam-dataflow.1583781343.474323/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpll6kh1wa', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://jeffersonballers-yeet/staging/artist-beam-dataflow.1583781343.474323/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://jeffersonballers-yeet/staging/artist-beam-dataflow.1583781343.474323/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://jeffersonballers-yeet/staging/artist-beam-dataflow.1583781343.474323/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T19:15:48.713414Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-09_12_15_47-229633684981361638'\n",
      " location: 'us-central1'\n",
      " name: 'artist-beam-dataflow'\n",
      " projectId: 'earnest-keep-266820'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T19:15:48.713414Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-09_12_15_47-229633684981361638]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-09_12_15_47-229633684981361638?project=earnest-keep-266820\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_12_15_47-229633684981361638 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:47.740Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-09_12_15_47-229633684981361638.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:47.740Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-09_12_15_47-229633684981361638. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:52.388Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:52.890Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:53.473Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:53.508Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 2/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:53.539Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:53.573Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input.tx/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:53.620Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:53.656Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:53.808Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.120Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.167Z: JOB_MESSAGE_DETAILED: Fusing consumer Replace t/f and n into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.194Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.228Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.270Z: JOB_MESSAGE_DETAILED: Fusing consumer Typecasts values to correct datatypes. into Replace t/f and n\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.309Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WriteBundles/WriteBundles into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.346Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Typecasts values to correct datatypes.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.376Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Pair into Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.411Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input.tx/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.441Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Reify into Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.465Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/Write into Write input.tx/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.498Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow into Write input.tx/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.531Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/Extract into Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.561Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.593Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.626Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.663Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.700Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.734Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.759Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Pair into Write log 2/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.791Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 2/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.827Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Reify into Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.862Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/Write into Write log 2/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.897Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 2/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.928Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/Extract into Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.961Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input.tx/Write/WriteImpl/InitializeWrite into Write input.tx/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:54.998Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.038Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 2/Write/WriteImpl/InitializeWrite into Write log 2/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.079Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.107Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.147Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.187Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.464Z: JOB_MESSAGE_DEBUG: Executing wait step start42\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.538Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.561Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.583Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.602Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.623Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.636Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.669Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.686Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.708Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.712Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.758Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.767Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.783Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:15:55.830Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_12_15_47-229633684981361638 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:16:23.271Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:17:52.231Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:17:52.261Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.226Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/DoOnce/Read+Write input.tx/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.289Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.323Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.398Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.424Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.448Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.461Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.491Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.497Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.537Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.569Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:23.610Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.168Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.233Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.274Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.346Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.383Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.409Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.422Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.428Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/DoOnce/Read+Write log 2/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.441Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.478Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.480Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.508Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.541Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.579Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.612Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.636Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.660Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.682Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.696Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.717Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.751Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.752Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.778Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.814Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:24.851Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:18:25.919Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_14256161703190790074\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_14256161703190790074\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:19:53.913Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_14256161703190790074\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:19:54.368Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_11146168108499823003\" started. You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_11146168108499823003\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:20:24.755Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_11146168108499823003\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:20:24.790Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_11146168108499823003\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:21:55.432Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:22:33.635Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_14256161703190787821\". You can check its status with the bq tool: \"bq show -j --project_id=earnest-keep-266820 dataflow_job_14256161703190787821\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:14.422Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_14256161703190787821\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:15.091Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Replace t/f and n+Write input.tx/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Typecasts values to correct datatypes.+Write log 2/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input.tx/Write/WriteImpl/Pair+Write input.tx/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input.tx/Write/WriteImpl/GroupByKey/Reify+Write input.tx/Write/WriteImpl/GroupByKey/Write+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write+Write log 2/Write/WriteImpl/Pair+Write log 2/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 2/Write/WriteImpl/GroupByKey/Reify+Write log 2/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:15.166Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:15.201Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:15.219Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:15.236Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:15.253Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:15.281Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:15.310Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:15.327Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:15.384Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:18.649Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:18.704Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:18.773Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:18.800Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:18.833Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:18.868Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:18.894Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:18.924Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:19.025Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.011Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/GroupByKey/Read+Write log 2/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 2/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.088Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.151Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.179Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.212Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.251Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.283Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.326Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.391Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.924Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/GroupByKey/Read+Write input.tx/Write/WriteImpl/GroupByKey/GroupByWindow+Write input.tx/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:20.996Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:21.074Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:21.103Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:21.127Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:21.162Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:21.203Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:21.233Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:21.304Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.045Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.111Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.177Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.238Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.249Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.303Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.341Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.378Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.417Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.457Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.510Z: JOB_MESSAGE_DEBUG: Value \"Write log 2/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:22.574Z: JOB_MESSAGE_BASIC: Executing operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:23.713Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:23.956Z: JOB_MESSAGE_BASIC: Finished operation Write log 2/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:24.212Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:24.284Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:24.358Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:24.426Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:24.493Z: JOB_MESSAGE_DEBUG: Value \"Write input.tx/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:24.562Z: JOB_MESSAGE_BASIC: Executing operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:25.789Z: JOB_MESSAGE_BASIC: Finished operation Write input.tx/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:25.856Z: JOB_MESSAGE_DEBUG: Executing success step success40\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:25.971Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:26.025Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:23:26.058Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:25:22.263Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:25:22.304Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T19:25:22.339Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-09_12_15_47-229633684981361638 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run 'beam programs'/Artist_Beam_Dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check primary key for artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1604371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  1604371"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from musicbrainz_modeled.Artist_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1604371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  1604371"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct artist_id) from musicbrainz_modeled.Artist_Beam_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check foreign keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(a.artist_id) from musicbrainz_modeled.Artist_Beam_DF as a\n",
    "right join musicbrainz_modeled.Recording_Beam_DF as r on r.artist_id = a.artist_id\n",
    "where a.artist_id is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(artist.artist_id) from musicbrainz_modeled.Artist_Beam_DF as artist\n",
    "right join musicbrainz_modeled.Release_Group_Beam_DF as rg on artist.artist_id = rg.artist_id\n",
    "where artist.artist_id is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(a.artist_id) from musicbrainz_modeled.Artist_Beam_DF as a\n",
    "right join musicbrainz_modeled.Release_Beam_DF as r on r.artist_id = a.artist_id\n",
    "where a.artist_id is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(a.artist_id) from musicbrainz_modeled.Artist_Beam_DF as a\n",
    "right join musicbrainz_modeled.Artist_Type as aty on aty.artist_type_id = a.artist_type\n",
    "where a.artist_type is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(a.gender) from musicbrainz_modeled.Artist_Beam_DF as a\n",
    "right join musicbrainz_modeled.Gender as g on g.gender_id = a.gender\n",
    "where a.gender is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
