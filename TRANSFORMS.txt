We have modeled our staging tables in the ERD diagram. This diagram also represents our modeled tables as well because our staging tables did / not require any transformations. That is to say that our staging tables already contained distinct entities and did not present any  / referential integrity violations nor contain duplicate records. Each table has a valid primary key, which we have identified in the ERD. /

We have some attributes that were incorrectly type casted as Strings by the bigquery autoload when the data tables were ingested. The dataset / uses the string “\N” to indicate null values, which has caused many fields that are supposed to be integers or timestamps to be marked as / String values by the big query autodetected schema. We have not type casted these attributes to their correct data types because of the / existence of the “\N” values in the columns. As a result, we will wait to replace “\N” values with actual nulls once we get to the data- / cleaning stage of the project where we use tools such as Beam. Once the “\N” values have been successfully removed we will be able to type cast the attributes to their correct types.

UPDATED (2/29/2020):
We have used beam to correct the "\N" values that exist in the Area data tabel's columns. These strings where replaced with python None / types, which bigqeuery interprets as nulls. Furthermore, attributes that were loaded as strings into the staging tables have been typecasted / to their most appropriate datatypes using our beam pipeline. To do this, the 'ended' attribute of the Area table had to have the 't' or 'f' / strings replaced with 'True' or 'False' before the attribute could be typecasted to boolean. We still have three tables, those of Work, / Event, and URL, that do not have relationships with other tables. We plan to use regular expressions to derive connections between these and / other tables that already have relationships. /

The event table has a start_time attribute that contains strings of event start times. We will need to type cast this to a format acceptable / for the TIME bigquery datatype when we get around to applying Beam transformations to the Event table. /

The year, month, day attributes found in many tables contain an inconsistent number of digits in there formatting. For example, what should / be the year '2019' in records may be trucated to just '19'. We will want to reformat these to a number of digits that is compatible with the / DATETIME bigquery datatype so that they can be concattenated these integer columns into a new column containing DATETIME values. /

For our secondary dataset, there were not many issues in the data. Each row had a data quality attribute that could be one of several
values and indicates the validity of the data in that row. We first removed any rows that had a data quality value of 'Entirely Incorrect'
in the discogs_staging notebook (since the tables were not yet modeling individual entities we didn't want to do it in the modeled
notebook).

The Label table in the secondary dataset has labels that can be sub-labels of other labels. However, some of the sub-labels reference
parent label keys which do not exist in the dataset. We will use beam to identify these and remove the incorrect parent information.
